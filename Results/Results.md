# Spark MLLib : testing the framework

## The data

for files of data :
* 4 000 lines (94.1 ko)
* 25 010 lines (613.7 ko)
* 100 000 lines (2.4 Mo)
* 1 000 000 lines (22 Mo)

## The algorithm

## Test protocol

during all the test, 70% of the dataset was randomly choose to train the model
and 30% to evaluate the model
roughly for training : 
* 2 800
* 17 500
* 70 000
* 700 000
roughly for evaluation :
* 1 200
* 7 500
* 30 000
* 300 000
